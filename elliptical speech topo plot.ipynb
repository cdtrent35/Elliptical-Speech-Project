{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# GLM Analysis (Measured)\n",
    "\n",
    "In this example we analyse data from a real multichannel\n",
    "functional near-infrared spectroscopy (fNIRS)\n",
    "experiment (see `tut-fnirs-hrf-sim` for a simplified simulated\n",
    "analysis). The experiment consists of three conditions:\n",
    "\n",
    "1. tapping with the left hand,\n",
    "2. tapping with the right hand,\n",
    "3. a control condition where the participant does nothing.\n",
    "\n",
    "We use a GLM analysis to examine the neural activity associated with\n",
    "the different tapping conditions.\n",
    "An alternative epoching style analysis on the same data can be\n",
    "viewed in the\n",
    "`waveform analysis example <tut-fnirs-processing>`.\n",
    "See\n",
    "[Luke et al (2021)](https://www.spiedigitallibrary.org/journals/neurophotonics/volume-8/issue-2/025008/Analysis-methods-for-measuring-passive-auditory-fNIRS-responses-generated-by/10.1117/1.NPh.8.2.025008.short)_\n",
    "for a comparison of the epoching and GLM approaches.\n",
    "\n",
    "This GLM analysis is a wrapper over the excellent\n",
    "[Nilearn GLM](http://nilearn.github.io/modules/reference.html#module-nilearn.glm)_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# sphinx_gallery_thumbnail_number = 9\n",
    "\n",
    "# Authors: Robert Luke <mail@robertluke.net>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "\n",
    "import mne_nirs\n",
    "from mne_nirs.channels import get_long_channels, get_short_channels, picks_pair_to_idx\n",
    "from mne_nirs.experimental_design import make_first_level_design_matrix\n",
    "from mne_nirs.statistics import run_glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import raw NIRS data\n",
    "\n",
    "First we import the motor tapping data, these data are also\n",
    "described and used in the\n",
    "`MNE fNIRS tutorial <mne:tut-fnirs-processing>`\n",
    "\n",
    "After reading the data we resample down to 1Hz\n",
    "to meet github memory constraints.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Optodes were placed over the motor cortex using the standard NIRX motor\n",
    "   montage, but with 8 short channels added (see their web page for details).\n",
    "   To view the sensor locations run ``raw_intensity.plot_sensors()``.\n",
    "   A sound was presented to indicate which hand the participant should tap.\n",
    "   Participants tapped their thumb to their fingers for 5s.\n",
    "   Conditions were presented in a random order with a randomised inter\n",
    "   stimulus interval.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fnirs_data_folder = mne.datasets.fnirs_motor.data_path()\n",
    "fnirs_raw_dir = os.path.join(fnirs_data_folder, \"Participant-1\")\n",
    "raw_intensity = mne.io.read_raw_nirx(fnirs_raw_dir).load_data()\n",
    "raw_intensity.resample(0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up annotations before analysis\n",
    "\n",
    "Next we update the annotations by assigning names to each trigger ID.\n",
    "Then we crop the recording to the section containing our\n",
    "experimental conditions.\n",
    "\n",
    "Because of limitations with ``nilearn``, we use ``'_'`` to separate conditions\n",
    "rather than the standard ``'/'``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "raw_intensity.annotations.rename(\n",
    "    {\"1.0\": \"Control\", \"2.0\": \"Tapping_Left\", \"3.0\": \"Tapping_Right\"}\n",
    ")\n",
    "raw_intensity.annotations.delete(raw_intensity.annotations.description == \"15.0\")\n",
    "raw_intensity.annotations.set_durations(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess NIRS data\n",
    "Next we convert the raw data to haemoglobin concentration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "raw_od = mne.preprocessing.nirs.optical_density(raw_intensity)\n",
    "raw_haemo = mne.preprocessing.nirs.beer_lambert_law(raw_od, ppf=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. sidebar:: Relevant literature\n",
    "\n",
    "   Tachtsidis, Ilias, and Felix Scholkmann. \"False positives and false\n",
    "   negatives in functional near-infrared spectroscopy: issues, challenges,\n",
    "   and the way forward.\" Neurophotonics 3.3 (2016): 031405.\n",
    "\n",
    "We then split the data in to\n",
    "short channels which predominantly contain systemic responses and\n",
    "long channels which have both neural and systemic contributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "short_chs = get_short_channels(raw_haemo)\n",
    "raw_haemo = get_long_channels(raw_haemo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View experiment events\n",
    "\n",
    "Next we examine the timing and order of events in this experiment.\n",
    "There are several options for how to view event information.\n",
    "The first option is to use MNE's plot events command.\n",
    "Here each dot represents when an event started.\n",
    "We observe that the order of conditions was randomised and the time between\n",
    "events is also randomised.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "events, event_dict = mne.events_from_annotations(raw_haemo, verbose=False)\n",
    "mne.viz.plot_events(events, event_id=event_dict, sfreq=raw_haemo.info[\"sfreq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous plot did not illustrate the duration that an event lasted for.\n",
    "Alternatively, we can view the experiment using a boxcar plot, where the\n",
    "line is raised for the duration of the stimulus/condition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "s = mne_nirs.experimental_design.create_boxcar(raw_haemo)\n",
    "fig, ax = plt.subplots(figsize=(15, 6), constrained_layout=True)\n",
    "ax.plot(raw_haemo.times, s)\n",
    "ax.legend([\"Control\", \"Left\", \"Right\"], loc=\"upper right\")\n",
    "ax.set_xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create design matrix\n",
    "\n",
    ".. sidebar:: Relevant literature\n",
    "\n",
    "   For further discussion on design matrices see\n",
    "   the Nilearn examples. Specifically the\n",
    "   [first level model example](http://nilearn.github.io/auto_examples/04_glm_first_level/plot_first_level_details.html)_.\n",
    "\n",
    "Next we create a model to fit our data to.\n",
    "The model consists of various components to model different things we assume\n",
    "contribute to the measured signal.\n",
    "We model the expected neural response for each experimental condition\n",
    "using the SPM haemodynamic response\n",
    "function (HRF) combined with the known stimulus event times and durations\n",
    "(as described above).\n",
    "We also include a cosine drift model with components up to the high pass\n",
    "parameter value. See the nilearn documentation for recommendations on setting\n",
    "these values. In short, they suggest \"The cutoff period (1/high_pass) should be\n",
    "set as the longest period between two trials of the same condition multiplied by 2.\n",
    "For instance, if the longest period is 32s, the high_pass frequency shall be\n",
    "1/64 Hz ~ 0.016 Hz\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "design_matrix = make_first_level_design_matrix(\n",
    "    raw_haemo,\n",
    "    drift_model=\"cosine\",\n",
    "    high_pass=0.005,  # Must be specified per experiment\n",
    "    hrf_model=\"spm\",\n",
    "    stim_dur=5.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the mean of the short channels to the design matrix.\n",
    "In theory these channels contain only systemic components, so including\n",
    "them in the design matrix allows us to estimate the neural component\n",
    "related to each experimental condition\n",
    "uncontaminated by systemic effects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "design_matrix[\"ShortHbO\"] = np.mean(\n",
    "    short_chs.copy().pick(picks=\"hbo\").get_data(), axis=0\n",
    ")\n",
    "\n",
    "design_matrix[\"ShortHbR\"] = np.mean(\n",
    "    short_chs.copy().pick(picks=\"hbr\").get_data(), axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we display a summary of the design matrix\n",
    "using standard Nilearn reporting functions.\n",
    "The first three columns represent the SPM HRF convolved with our stimulus\n",
    "event information.\n",
    "The next columns illustrate the drift and constant components.\n",
    "The last columns illustrate the short channel signals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6), constrained_layout=True)\n",
    "fig = plot_design_matrix(design_matrix, ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine expected response\n",
    "\n",
    "The matrices above can be a bit abstract as they encompase multiple\n",
    "conditions and regressors.\n",
    "Instead we can examine a single condition.\n",
    "Here we observe the boxcar function for a single condition,\n",
    "this illustrates when the stimulus was active.\n",
    "We also view the expected neural response using the HRF specified above,\n",
    "we observe that each time a stimulus is presented there is an expected\n",
    "brain response that lags the stimulus onset and consists of a large positive\n",
    "component followed by an undershoot.\n",
    "\n",
    "In this example the second trigger (index 1) corresponds to the ``Tapping/Left``\n",
    "condition in the design matrix, so we plot those below. In your data the mapping\n",
    "may be different, so you may need to alter either the ``s`` index or condition\n",
    "name. Note however, that this is just for visualisation and does not affect\n",
    "the results below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(constrained_layout=True)\n",
    "s = mne_nirs.experimental_design.create_boxcar(raw_intensity, stim_dur=5.0)\n",
    "ax.plot(raw_intensity.times, s[:, 1])\n",
    "ax.plot(design_matrix[\"Tapping_Left\"])\n",
    "ax.legend([\"Stimulus\", \"Expected Response\"])\n",
    "ax.set(xlim=(180, 300), xlabel=\"Time (s)\", ylabel=\"Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit GLM to subset of data and estimate response for each experimental condition\n",
    "\n",
    ".. sidebar:: Relevant literature\n",
    "\n",
    "   Huppert TJ. Commentary on the statistical properties of noise and its\n",
    "   implication on general linear models in functional near-infrared\n",
    "   spectroscopy. Neurophotonics. 2016;3(1)\n",
    "\n",
    "We run a GLM fit for the data and experiment matrix.\n",
    "First we analyse just the first two channels which correspond to HbO and HbR\n",
    "of a single source detector pair.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_subset = raw_haemo.copy().pick(picks=range(2))\n",
    "glm_est = run_glm(data_subset, design_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a GLM regression estimate for each channel.\n",
    "This data is stored in a dedicated type.\n",
    "You can view an overview of the estimates by addressing the variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with other MNE types you can use the `pick` function.\n",
    "To query the mean square error of a single channel you would call.\n",
    "\n",
    "Note: as we wish to retain both channels for further the analysis below,\n",
    "we operate on a copy to demonstrate this channel picking functionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est.copy().pick(\"S1_D1 hbr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underlying the data for each channel is a standard\n",
    "[Nilearn RegressionResults object](https://nilearn.github.io/modules/generated/nilearn.glm.RegressionResults.html)\n",
    "object. These objects are rich with information that can be requested\n",
    "from the object, for example to determine the mean square error of the\n",
    "estimates for two channels you would call:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est.MSE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can chain the methods to quickly access required details.\n",
    "For example, to determine the MSE for channel `S1` `D1` for the hbr type\n",
    "you would call:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est.copy().pick(\"S1_D1 hbr\").MSE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the richness of the objects we provide a function to\n",
    "extract commonly used information and put it in a convenient dataframe/table.\n",
    "Below this is demonstrated and then we just display the first 9 rows of the\n",
    "table which correspond to the 9 components of the design matrix for the\n",
    "first channel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est.to_dataframe().head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then display the results using the scatter plot function.\n",
    "Note that the control condition sits\n",
    "around zero\n",
    "and that the HbO is positive and larger than the HbR, this is to be expected.\n",
    "Further, we note that for this channel the response to tapping on the\n",
    "right hand is larger than the left. And the values are similar to what\n",
    "is seen in the epoching tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit GLM to all data and view topographic distribution\n",
    "\n",
    "Lastly we can run the GLM analysis on all sensors and plot the result on a\n",
    "topomap.\n",
    "We see the same result as in the MNE tutorial,\n",
    "that activation is largest\n",
    "contralateral to the tapping side. Also note that HbR tends to be the\n",
    "negative of HbO as expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est = run_glm(raw_haemo, design_matrix)\n",
    "glm_est.plot_topo(conditions=[\"Tapping_Left\", \"Tapping_Right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the topographic visualisation is a high level representation\n",
    "of the underlying data. This visual representation fits a smoothed surface\n",
    "to the data and makes many assumptions including that the data is\n",
    "spatially smooth and that the sensors sufficiently cover the scalp surface.\n",
    "These assumptions can be violated with fNIRS due to the improved spatial\n",
    "sensitivity (relative to EEG) and typically low number of sensors that are\n",
    "unevenly distributed over the scalp.\n",
    "As such, researchers should understand the underlying data and ensure that\n",
    "the figure accurately reflects the effect of interest.\n",
    "\n",
    "As an example of how the topoplot can be deceiving, we replot\n",
    "the `Tapping/Right` condition from above for each hemisphere\n",
    "separately. When both hemisphere are plotted together (left),\n",
    "the function smooths\n",
    "the large space between sensors, making the activity on the left hemisphere\n",
    "smear towards the center and appear larger than the underlying data shows.\n",
    "When each hemisphere is plotted independently (right) it becomes immediately\n",
    "apparent that the data does not indicate that activity spreads across\n",
    "the center of the head.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(10, 6), gridspec_kw=dict(width_ratios=[0.92, 1])\n",
    ")\n",
    "\n",
    "glm_hbo = glm_est.copy().pick(picks=\"hbo\")\n",
    "conditions = [\"Tapping_Right\"]\n",
    "\n",
    "glm_hbo.plot_topo(axes=axes[0], colorbar=False, conditions=conditions)\n",
    "\n",
    "glm_hbo.copy().pick(picks=range(10)).plot_topo(\n",
    "    conditions=conditions, axes=axes[1], colorbar=False, vlim=(-16, 16)\n",
    ")\n",
    "glm_hbo.copy().pick(picks=range(10, 20)).plot_topo(\n",
    "    conditions=conditions, axes=axes[1], colorbar=False, vlim=(-16, 16)\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Smoothed across hemispheres\")\n",
    "axes[1].set_title(\"Hemispheres plotted independently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to view the data is to project the GLM estimates to the nearest\n",
    "cortical surface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "glm_est.copy().surface_projection(\n",
    "    condition=\"Tapping_Right\", view=\"dorsal\", chroma=\"hbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse regions of interest\n",
    "\n",
    ".. sidebar:: Relevant literature\n",
    "\n",
    "   Zimeo Morais, G.A., Balardin, J.B. & Sato, J.R.\n",
    "   fNIRS Optodesâ€™ Location Decider (fOLD): a toolbox for probe arrangement\n",
    "   guided by brain regions-of-interest. Sci Rep 8, 3341 (2018).\n",
    "\n",
    "   Shader and Luke et al. \"The use of broad vs restricted regions of\n",
    "   interest in functional near-infrared spectroscopy for measuring cortical\n",
    "   activation to auditory-only and visual-only speech.\"\n",
    "   Hearing Research (2021): [108256](https://www.sciencedirect.com/science/article/pii/S0378595521000903).\n",
    "\n",
    "Or alternatively we can summarise the responses across regions of interest\n",
    "for each condition. And you can plot it with your favorite software.\n",
    "Region of interest analysis can be more robust than single channel analysis.\n",
    "The fOLD toolbox can be used to assist in the design of ROIs.\n",
    "And consideration should be paid to ensure optimal size ROIs are selected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "left = [[1, 1], [1, 2], [1, 3], [2, 1], [2, 3], [2, 4], [3, 2], [3, 3], [4, 3], [4, 4]]\n",
    "right = [[5, 5], [5, 6], [5, 7], [6, 5], [6, 7], [6, 8], [7, 6], [7, 7], [8, 7], [8, 8]]\n",
    "\n",
    "groups = dict(\n",
    "    Left_ROI=picks_pair_to_idx(raw_haemo, left),\n",
    "    Right_ROI=picks_pair_to_idx(raw_haemo, right),\n",
    ")\n",
    "\n",
    "conditions = [\"Control\", \"Tapping_Left\", \"Tapping_Right\"]\n",
    "\n",
    "df = glm_est.to_dataframe_region_of_interest(groups, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the single channel results above, this is placed in a tidy dataframe\n",
    "which contains conveniently extracted information, but now for the region\n",
    "of interest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute contrasts\n",
    "\n",
    "We can also define a contrast as described in\n",
    "[Nilearn docs](http://nilearn.github.io/auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html)_\n",
    "and plot it.\n",
    "Here we contrast the response to tapping on the left hand with the response\n",
    "from tapping on the right hand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "basic_conts = dict(\n",
    "    [(column, contrast_matrix[i]) for i, column in enumerate(design_matrix.columns)]\n",
    ")\n",
    "contrast_LvR = basic_conts[\"Tapping_Left\"] - basic_conts[\"Tapping_Right\"]\n",
    "\n",
    "contrast = glm_est.compute_contrast(contrast_LvR)\n",
    "contrast.plot_topo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    ".. sidebar:: Relevant literature\n",
    "\n",
    "   Wickham, Hadley. \"Tidy data.\" Journal of Statistical Software 59.10 (2014): 1-23.\n",
    "\n",
    "Here we export the data in a tidy pandas data frame.\n",
    "We export the GLM results for every channel and condition.\n",
    "Data is exported in long format by default.\n",
    "However, a helper function is also provided to convert the long data to wide format.\n",
    "The long to wide conversion also adds some additional derived data, such as\n",
    "if a significant response (p<0.05) was observed, which sensor and detector is\n",
    "in the channel, which chroma, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = glm_est.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine true and false positive rates\n",
    "\n",
    "We can query the exported data frames to determine the true and false\n",
    "positive rates. Note: optodes cover a greater region than just the\n",
    "motor cortex, so we dont expect 100% of channels to detect responses to\n",
    "the tapping, but we do expect 5% or less for the false positive rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df.query('Condition in [\"Control\", \"Tapping_Left\", \"Tapping_Right\"]')\n",
    "    .drop([\"df\", \"mse\", \"p_value\", \"t\"], axis=1)\n",
    "    .groupby([\"Condition\", \"Chroma\", \"ch_name\"])\n",
    "    .agg([\"mean\"])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
